<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zhuangzi Li - Academic Homepage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            background: #333;
            color: #fff;
            padding: 1rem 0;
            text-align: center;
        }
        header h1 {
            margin: 0;
            font-size: 2.5rem;
        }
        header p {
            margin: 0;
            font-size: 1.2rem;
        }
        nav {
            background: #444;
            color: #fff;
            display: flex;
            justify-content: center;
            padding: 0.5rem 0;
        }
        nav a {
            color: #fff;
            text-decoration: none;
            margin: 0 1rem;
            font-size: 1rem;
        }
        nav a:hover {
            text-decoration: underline;
        }
        main {
            padding: 2rem;
            max-width: 800px;
            margin: 0 auto;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        section {
            margin-bottom: 2rem;
        }
        section h2 {
            border-bottom: 2px solid #333;
            padding-bottom: 0.5rem;
        }
        footer {
            text-align: center;
            background: #333;
            color: #fff;
            padding: 1rem 0;
            margin-top: 2rem;
        }
        footer p {
            margin: 0;
        }
    </style>
</head>
<body>
    <header>
        <h1>Zhuangzi Li</h1>
        <p>Postdoctoral Researcher | 3D Vision | Nanyang Technological University</p>
    </header>

    <nav>
        <a href="#about">About</a>
        <a href="#research">Research</a>
        <a href="#publications">Publications</a>
        <a href="#contact">Contact</a>
    </nav>

    <main>
        <section id="about">
            <h2>About Me</h2>
            <p>Welcome to my academic homepage! I am a postdoctoral researcher specializing in 3D vision at Nanyang Technological University. My research focuses on advanced techniques in computer vision and video super-resolution. You can find more details on my <a href="https://scholar.google.com/citations?user=m71dVWIAAAAJ&hl=zh-CN" target="_blank">Google Scholar profile</a>.</p>
        </section>

        <section id="research">
            <h2>Research Interests</h2>
            <ul>
                <li>3D Vision and Reconstruction</li>
                <li>Video Super-Resolution</li>
                <li>Machine Learning and Deep Learning</li>
                <li>Point Cloud Processing</li>
            </ul>
        </section>

        <section id="publications">
            <h2>Publications</h2>
            <p>Here is a selection of my recent publications:</p>
            <ul>
                <li>X Zhu, Z Li, XY Zhang, C Li, Y Liu, Z Xue, "Residual invertible spatio-temporal network for video super-resolution," <em>AAAI Conference on Artificial Intelligence</em>, 2019. Cited by 80. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>X Zhu, Z Li, X Li, S Li, F Dai, "Attention-aware perceptual enhancement nets for low-resolution image classification," <em>Information Sciences</em>, 2020. Cited by 46. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>X Zhu, Z Li, J Lou, Q Shen, "Video super-resolution based on a spatio-temporal matching network," <em>Pattern Recognition</em>, 2021. Cited by 41. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, G Li, TH Li, S Liu, W Gao, "Semantic point cloud upsampling," <em>IEEE Transactions on Multimedia</em>, 2022. Cited by 38. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>X Zhu, Z Li, X Zhang, H Li, Z Xue, L Wang, "Generative adversarial image super‚Äêresolution through deep dense skip connections," <em>Computer Graphics Forum</em>, 2018. Cited by 30. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, G Li, T Li, S Liu, W Gao, "Information-growth attention network for image super-resolution," <em>ACM International Conference on Multimedia</em>, 2021. Cited by 24. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, X Zhu, L Wang, P Guo, "Image classification using convolutional neural networks and kernel extreme learning machines," <em>ICIP</em>, 2018. Cited by 19. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>S Li, Q Cai, H Li, J Cao, L Wang, Z Li, "Frequency separation network for image super-resolution," <em>IEEE Access</em>, 2020. Cited by 18. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>X Zhu, Z Li, XY Zhang, P Li, Z Xue, L Wang, "Deep convolutional representations and kernel extreme learning machines for image classification," <em>Multimedia Tools and Applications</em>, 2019. Cited by 18. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, "Image super-resolution using attention based densenet with residual deconvolution," <em>arXiv preprint</em>, 2019. Cited by 13. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, S Li, N Zhang, L Wang, Z Xue, "Multi-scale invertible network for image super-resolution," <em>ACM Multimedia in Asia</em>, 2019. Cited by 6. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>H Yu, Z Li, W Guo, D Li, L Wang, Y Wang, "An estimation method of maize impurity rate based on the deep residual networks," <em>Industrial Crops and Products</em>, 2023. Cited by 4. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>S Li, Q Cai, Z Li, H Li, N Zhang, J Cao, "Attention-aware invertible hashing network," <em>Image and Graphics</em>, 2019. Cited by 3. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>S Li, Q Cai, Z Li, H Li, N Zhang, X Zhang, "Attention-aware invertible hashing network with skip connections," <em>Pattern Recognition Letters</em>, 2020. Cited by 2. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, S Liu, G Li, "PointELM: Fast Point Cloud Classification Using Deep Random Mapping Based Extreme Learning Machines," <em>ICME</em>, 2024. Cited by 1. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>Z Li, F Dai, N Zhang, L Wang, Z Xue, "Representative Feature Matching Network for Image Retrieval," <em>ACM Multimedia in Asia</em>, 2019. Cited by 1. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>H Yu, Z Li, W Li, W Guo, D Li, L Wang, M Wu, Y Wang, "A Tiny Object Detection Approach for Maize Cleaning Operations," <em>Foods</em>, 2023. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
                <li>F Dai, Z Li, N Zhang, Q Wang, X Zhu, P Li, "Deep Super-Resolution Hashing Network for Low-Resolution Image Retrieval," <em>Image and Graphics</em>, 2019. [<a href="#">PDF</a> | <a href="#">DOI</a>]</li>
            </ul>
            <p>For a full list of my publications, visit my <a href="https://scholar.google.com/citations?user=m71dVWIAAAAJ&hl=zh-CN" target="_blank">Google Scholar profile</a>.</p>
        </section>

        <section id="contact">
            <h2>Contact</h2>
            <p>If you would like to get in touch, feel free to email me at <a href="mailto:your_email@example.com">zhuangzi.li@ntu.edu.sg</a>.</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2024 Zhuangzi Li. All Rights Reserved.</p>
    </footer>
</body>
</html>
